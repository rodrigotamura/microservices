# Kubernetes

## Introdu√ß√£o

Kubertnetes √© um orquestrador, ou gerenciador de containers riqu√≠ssimo em recursos.

> Kubernetes √© um produto Open Source para automatizar a implanta√ß√£o, o dimensionamento e o gerenciamento de aplicativos em cont√™iner. (Fonte: https://kubernetes.io/pt)

### De onde veio?

O Kubernetes veio da Google, com um nome inicial de *Borg*, evoluindo para *Omega* e finalmente evoluido para Kubernetes. Portanto, n√£o √© a toa que os melhores Clods Providers para Kubernetes √© a pr√≥pria Google.

### Pontos importantes

- Kubernetes √© disponibilizado atrav√©s de um conjunto de APIs, ou seja, tudo o que fizermos no Kubernetes, no final das contas, s√£o feitos via endpoints de API (cria√ß√£o de deployment, servi√ßos, PODs, etc.);
- Por√©m, ao inv√©s de ficarmos usando esta APIs podemos usar um CLI: **kubectl**;
- Tudo √© baseado em estado, onde teremos v√°rios objetos e cada objeto tem um estado, e baseado no estado deste objeto o Kubernetes toma determinadas a√ß√µes;
- O Kubernetes trabalha atrav√©s de **clusters**, que √© um conjunto de m√°quinas que juntas possui um poder computacional para realizar diversos tipos de tarefas. Especificamente no caso do Kubernetes, possui um cluster chamado **_master_** que controla os processos que os outros n√≥s ir√£o fazer. O *master* possui alguns servi√ßos dispon√≠veis:
    - Kube-apiserver;
    - Kube-controller-manager;
    - Kube-scheduler;
- Outros n√≥s que n√£o s√£o *master*:
    - Kubelet;
    - Kubeproxy.

### Din√¢mica "Superficial"

Vamos fazer uma an√°lise BEM SUPERFICIAL de como o Kubertnete funciona.

![Overview Kubernetes](kubernetes-intro.png)

(o quadrado cinza representa um *cluster*)

O Kubernetes possui o conhecimento da capacidade computacional de cada *node*, o que faz com que ele consiga provisionar os recursos necess√°rios para as tarefas.

![PODs](pod.png)

Normalmente √© um POD por container e s√£o raras as exce√ß√µes de um POD conter mais de um container rodando.

### Deployment

√â um outro tipo de "objeto" de Kubernetes com o objetivo de provisionar os PODs. Para esta provis√£o, o Kubertnetes precisa saber quantas r√©plicas destes PODs ser√£o disponibilizados. Ent√£o temos o termo **replica sets**, onde setamos quantas r√©plicas queremos de cada *set* de POD. Mas normalmente agente consegue setar estas r√©plicas sets dentro da mesma descri√ß√£o do pr√≥prio *deployment*.

No esquema abaixo, temos uma aplica√ß√£o *backend* (B) e *frontend* (F), onde numa primeira etapa o *deployment* provisionou dentro de um n√≥ (quadrado cinza) 3 r√©plicas para o B e 2 r√©plicas para o F. Num segundo momento houve uma necessidade de se escalar o F para 3 r√©plicas. E num terceiro e √∫ltimo momento foi necess√°rio escalar o B para 4 r√©plicas, por√©m n√£o houveram mais provisionamento do *deployment* pois n√£o existem mais recursos computacionais. Ent√£o este 4¬∫ POD vai ficar pendente at√© que surja mais n√≥s ou que este n√≥s tenha mais recursos.

![Deployment](deployment.png)

Mas vamos imaginar que foi adicionado mais um n√≥ neste *cluster* e o mesmo est√° vazio. Ent√£o o Kubernetes, atrav√©s do *deployment* vai adicionar o POD que estava pendente.

![Deployment Nodes](deployment-nodes.png)

Vamos supor que um destes n√≥s ficou fora do ar. O Kubernetes vai provisionar os PODs que est√£o fora do ar no n√≥s qu eest√° funcionando, por√©m alguns PODs v√£o ficar de fora pois n√£o caber√£o todos, ficando assim aguardando novos n√≥s ou aumento dos recursos no atual n√≥.

## Entendendo Services

Services √© a interface de comunica√ß√£o entre o ambiente externo e os nossos PODs. Afinal, se tivermos v√°rios PODs como saberei qual acessar? Ent√£o os *Services* nos ajudam nesta demanda.

> *Services* √© uma forma de agregar um conjunto de PODs para ent√£o implementar pol√≠ticas de visibilidade. Atrav√©s das pol√≠ticas de visibilidade adotada iremos expor os nossos PODs.

Existem tr√™s tipos principais de services, aos quais veremos a seguir.

### Services - ClusterIP

√â o *service* padr√£o quando criado no Kubernetes. 

![ClusterIP](services-clusterip.png)

Imaginamos que temos um tr√°fego da rede entrando, ent√£o temos um *proxy* que sabe em qual *service* mandar, e logo temos um *service* que aponta para os PODs.

Partimos da regra que os PODs se comunicam entre si e n√£o possui um acesso direto ao mundo externo. Ent√£o teremos um IP virtual gerada pelo *cluster* e tudo que roda ali dentro, no final das contas, acontece de forma interna.

### Services - NodePort

Diferente do ClusterIP, este tipo de *service* n√£o trabalha com *proxy*.

![NodePort](services-nodeport.png)

Ent√£o temos uma carga externa de tr√°fego vindo, ent√£o n√≥s temos os n√≥s (node da m√°quina 1, node da m√°quina 2, etc.) e uma porta espec√≠fica. Esta carga de tr√°fego cair√° em uma determinada porta e, independente de qual porta cair, ser√° encaminhado para um *service* que apontar√° para os PODs.

Ent√£o n√£o temos um *proxy* para rotear, mas sim v√°rias portas que s√£o atribu√≠das para cada servi√ßo. Se em algum momento cair na porta, por exemplo 3001, n√£o importa qual node que cair este tr√°fego, automaticamente o Kubernetes sabe que ele tem que redirecionar para um determinado servi√ßo.

### Service - LoadBalancer

A ideia principal √© export um IP externo e a carga do tr√°fego cair√° neste *LoadBalancer*, que far√° toda a distriui√ß√£o de carga, inclusive para saber em qual n√≥ ele encaminhar√° o acesso.

No ClusterIP n√£o temos acesso externo, somente para dentro do *cluster*. Se estivermos com o NodePort na mesma rede e mandarmos um tr√°fego para qualquer um dos nodes naquela porta, o mesmo receber√° e o LoadBalancer garantir√° isso do lado de fora.

### Selectors

Mas **como saberemos que determinados PODs pertence a determinado _service_?**

Para isso temos os **_Selectors_**, que ser√° definido no *service* para fazer um filtro de verifica√ß√£o para saber quais PODs ele vai colocar dentro daquele servi√ßo.

![Services - Selectors](services-selectors.png)

Assim temos uma ideia de como podemos selecionar os PODs dentro de um servi√ßo atrav√©s de *selectors* que definiremos as propriedades e que podem ser v√°rias. Vamos supor que temos *backends* em NOdeJS na vers√£o X com a propriedade Z. Podemos colocar todas estas informa√ß√µes no *seletor*. Quando formos criar os services conseguimos fazer esses filtros e ele vai buscar todos os PODs com estas caracter√≠sticas para gerar o *service* deixando tudo dispon√≠vel.

## Minikube

Com o Minikube podemos criar uma m√°quina virtual com o *Singlenode Kubernetes* rodando dentro dele na nossa m√°quina, para que possamos fazer a pr√°tica em Kubernetes. Salienta-se que os recursos s√£o bem limitados, n√£o ter√° dispon√≠vel o *LoadBalancer*, etc. Mas √© totalmente vi√°vel testarmos as opera√ß√µes b√°sicas.

### Instala√ß√£o

Acesse [este link](https://kubernetes.io/docs/tasks/tools/install-minikube/) para iniciar a instala√ß√£o do Minikube.

> üëâ Como m√°quina virtual estaremos utilizando o **VirtualBox**.

Lembrando que tamb√©m precisamos [instalar o **kubectl**](https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-linux).

Para inicializar o Minikube temos que executar o comando `minikube start` (na primeira execu√ß√£o poder√° demorar um pouco).

> O **kubectl** √© um *client* do Kubernetes para se comunicar com algum *cluster* do Kubernetes. Nele podemos configurar arquivos de configura√ß√£o que setam cada *namespace* para estabelecermos a comunica√ß√£o com determinado *cluster*. Podemos ent√£o configurar um ambiente para que o *kubectl* se comunique com o *cluster* 1, ou o *cluster 2*, ou o *cluster* na Amazon, no GCP, no Minikube, etc. E nestes arquivos de configura√ß√£o temos um certificado que garante que o kubectl tem autoriza√ß√£o para acessar determinados *clusters* de Kubertnetes.

Ap√≥s inicializado o Minikube, note que aparecer√° a mensagem que *kubectl is now configured to use "minikube"*, ou seja, todos os comandos de `kubectl` que executarmos est√° configurado para o Minikube.

Para listarmos os *services* do nosso Minikube, vamos executar: `kubectl get svc` que retornar√° o seguinte:

```
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   9m25s
```

Retornou um elemento chamado **kubernetes**, do tipo **ClusterIP** (s√≥ possui comunica√ß√£o interna por dentro do *cluster*), note que n√£o tem IP externo, mas somente o interno.

## Criando primeiro POD

Neste t√≥pico iremos aberdar como se cria um POD, por√©m, no dia a dia n√£o vamos sair e ir criando PODs, mas sim vamos criar um *Deployment* e ele ser√° respons√°vel por criar os PODs.

Vamos criar um arquivo chamado [pod.yaml](pod.yaml). Abra-o para visualizar os detalhamentos.

Ap√≥s configurado o arquivo acima, vamos rodar o seguinte comando:

`kubectl apply -f pod.yaml`

- `apply`: para aplicar este arquivo, aplicando sempre as novas altera√ß√µes caso houver;
- `-f <nome-arquivo>`: declarando que vamos indicar um arquivo.

Caso d√™ tudo certo aparecer√° a mensagem `pod/pod-exemplo created` üëç

Executando o comando `kubectl get pods` listar√£o os PODs e retornar√° o seguinte:

```
NAME          READY   STATUS    RESTARTS   AGE
pod-exemplo   1/1     Running   0          101s
```

O comando `kubectl logs pod-exemplo` retornar√° poss√≠veis erros. Se n√£o retornar algo significa que o POD subiu sem problemas üòâ.

Mas, **_como faremos para acessar este container do NGINX que criamos dentro deste POD?_**

Lembra que, como foi abordado ontem, todo o tr√°fego que precisa acessar √© necess√°rio ter um *service*, possuindo os tr√™s tipos - ClusterIP, LoadPort e LoadBBalancer. No pr√≥ximo t√≥pico vamos matar este POD rec√©m criado, vamos criar um *Deployment*, e atrav√©s deste vamos criar um novo POD e depois vamos criar um *Service* para expor este *Deployment* onde tem os PODs rodando para poder acessar via browser o servi√ßo do NGINX.

## Trabalhando com *Deployments*

N√£o √© recomendado criar PODs como no t√≥pico anterior, pois s√≥ foi para quest√µes did√°ticas.

Aqui vamos criar um *Deployment* que pega um conjunto de PODs (vamos definir isso na parte de r√©plicas), qual a imagem que ele vai utilizar e quando formos *subir* o *deployment* os PODs ser√£o criados automaticamente.

Vamos criar o *Deployment* de duas formas. A primeira forma √© via linha de comando, pois tudo que agente escreve no arquivo YAML podemos executar via linha de comando. Obviamente que na pr√°tica n√£o conv√©m optar por isso. Mas o recomendado √© a segunda forma, onde utilizaremos um arquivo declarativo YAML.

### Deployment utilizando a linha de comando

Execute inicialmente o comando `kubectl create deployment hello-nginx --image=nginx:1.17-alpine`, onde: 

- `hello-nginx` seria o nome do *deployment*;
- `--image=<nome-imagem>` indica a imagem que ser√° utilizada

Ao executar o comando acima, se der tudo certo, aparecer√° a seguinte mensagem:

`deployment.apps/hello-nginx created`

Para listar os *deployments* vamos digitar `kubectl get deployments` que retornar√° o seguinte:

```
NAME          READY   UP-TO-DATE   AVAILABLE   AGE
hello-nginx   1/1     1            1           82s
```
(a coluna `READY` indica que existe 1 POD de 1 rodando)

Perceba que ao executarmos `kubectl get pods` ser√£o listados todos os PODs que temos:

```bash
NAME                           READY   STATUS    RESTARTS   AGE
hello-nginx-6485484cdf-2ztwg   1/1     Running   0          2m20s
pod-exemplo                    1/1     Running   0          29m
```

O POD `hello-nginx-6485484cdf-2ztwg` foi criado pelo *deployment*.

Perceba que um *deployment* tem um *replicaSet* e este pode escolher quantos PODs ele quer ter dispon√≠vel.

**Agora vamos criar um _SERVICE_** e a partir dele vamos conseguir acessar o POD que est√° dentro deste *deployment*.

> Lembrando que estamos fazendo via linha de comando. Mais adiante vamos implementar tudo isso via arquivo declarativo.

Criando o *service* para acesso ao POD:

`kubectl expose deployment hello-nginx --type=LoadBalancer --port=80`

- `expose`: comando para expor algo;
- `deployment <nome-deployment>`: indicando o que queremos expor, neste caso seria o *deployment*;
- `--type=<service-type>`: LoadBalancer / LoadPort / ClusterIP. O Minikube n√£o possui a op√ß√£o LoadBalancer, mas mais adiante vamos entrar em mais detalhes.
- `--port=<num-porta>`: em qual porta vamos expor para acesso externo.

Caso d√™ tudo certo ser√° retornado o seguinte:

`service/hello-nginx exposed`

Ao executar o comando para listar os *services* via `kubectl get services`, ser√° retornado o seguinte:

```
NAME          TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
hello-nginx   LoadBalancer   10.107.76.245   <pending>     80:31052/TCP   3m23s
kubernetes    ClusterIP      10.96.0.1       <none>        443/TCP        16h
```

Note que foi criado o `hello-nginx`, o IP `10.107.76.245` indica o IP do cluster, o `EXTERNAL-IP` est√° como pendente pois n√£o vai gerar. Ali na coluna `PORT(S)` est√° declarando que ao acessar a porta 31052 o *service* redirecionar√° para a porta 80 do POD.

O seguinte comando do Minikube realizar√° o acesso para o POD:

`minikube service hello-nginx`

Voc√™ notar√° que o navegador ser√° aberto com o endere√ßo para acesso ao POD e retornando o seguinte:

```
|-----------|-------------|-------------|-------------------------|
| NAMESPACE |    NAME     | TARGET PORT |           URL           |
|-----------|-------------|-------------|-------------------------|
| default   | hello-nginx |          80 | http://172.17.0.2:31052 |
|-----------|-------------|-------------|-------------------------|
üéâ  Opening service default/hello-nginx in default browser...
```

Perceba que o IP aberto no navegador n√£o √© o mesmo que o indicado no *cluster IP*. Na verdado o IP indicado no navegador foi gerado pelo pr√≥prio Minikube.

### Deployment via arquivo declarativo

Esta √© a forma normal de sere criado um *deployment*.

Vamos criar um arquivo chamado [deployment.yaml](deployment.yaml).

Antes de colocar no ar o *Deployment* configurado via YAML, vamos "matar" todos os outros *Deployments* criados anteriormente via comando:

`kubectl delete deployments --all`

Agora vamos executar o seguinte comando para colocarmos no ar o *Deployment* criado: `kubectl apply -f deployment.yaml` ent√£o retornar√° uma resposta notificando que o *deployment* foi criado.

## Criando nosso Service

Agora vamos criar no formato de arquivo declarativo o nosso *Service*.

Vamos criar o arquivo chamado [service.yaml](service.yaml). Acesse este arquivo para maiores explica√ß√µes e detalhes.

Logo ap√≥s vamos rodar o comando `kubectl apply -f service.yaml` e, se n√£o deu nenhum retorno de erro, execute `minikube service nginx-service`.

**ATEN√á√ÉO:** caso o POD indicado no `spec.selector` n√£o encontrar nenhuma key `app:hello-nginx` logicamente o servi√ßo quando acessado via `minikube service nginx-service` estar√° fora do ar.

## Escalando PODs

Existem alguns questionamentos que surgem quando subimos nossos *deployments* contendo os containers nos PODs do Kubernetes.

**_Se este POD por algum motivo "morrer, o que vai acontecer?"_**
O Kubernetes perceber√° que um POD morreu ent√£o ele vai tentar subir novamente um novo POD. Mas se quisermos GARANTIR que nada fique fora do ar (pois o tempo entre a morte e subir um POD haver√° um *downtime*) teremos que **adicionar novos PODs**, e a adi√ß√£o de outros PODs podem garantir tamb√©m o atendimento de mais tr√°fegos.

Vamos neste t√≥pico trabalhar com **R√âPLICAS**.

Abramos o arquivo [deployment.yaml](deployment.yaml), e vamos acrescentar a configura√ß√£o `specs.replicas`. Abra o arquivo para maiores detalhes e explica√ß√µes.

Veja que, ap√≥s a aplica√ß√£o desta configura√ß√£o que ir√° gerarr 3 r√©plicas, ao subir este *deployment* e logo ap√≥s listar os PODs voc√™ ver√° que haver√£o 3 PODs rodando:

```
NAME                          READY   STATUS    RESTARTS   AGE
hello-nginx-dbd45bd76-7fq68   1/1     Running   0          22m
hello-nginx-dbd45bd76-bgmxj   1/1     Running   0          8s
hello-nginx-dbd45bd76-qm2sk   1/1     Running   0          8s
```

E veja que, atrav√©s do comando `kubectl get deployments` retornar√£o 3/3 PODs:

```
NAME          READY   UP-TO-DATE   AVAILABLE   AGE
hello-nginx   3/3     3            3           84m
```

O Kubernetes tamb√© possui o recurso de **auto-scaling**, por√©m n√£o iremos abordar sobre este assunto.

Lembrando que n√£o podemos ficar aumentando o n√∫mero de r√©plicas pois os n√≥s possuem recursos limitados (CPU, RAM, etc.). Quando um n√≥ est√° no limite e mais r√©plicas s√£o criadas, o Kubernetes vai procurar por novos nodes que estejam dispon√≠veis no *cluster*.

## Trabalhando com ConfigMap

Quando trabalhamos com Docker, pod√≠amos realizar o mapeamento dos arquivos e aplicando configura√ß√µes para dentro de uma imagem atrav√©s do Dockerize.

Mas como poder√≠amos fazer isso trabalhando com o Kubernetes?

Na pr√°tica deste t√≥pico, vamos continuar trabalhando com o NGINX, por√©m alterando criando dentro das configura√ß√µes um par√¢metro de redirecionamento. Ent√£o toda vez que agente acessar o endere√ßo que o Kubernetes vai disponibilizar para acesso seguido pelo `/google` (ex.: http://192.168.0.87/google), o NGINX vai reescrever esta URL e redirecionar para o site da Google.

Para isso vamos utilizar o **ConfigMap**, que √© mais um objeto/arquivo do Kubernetes que nos auxiliar√° a colocar qualquer tipo de dados, documentos, veri√°veis, arquivos (at√© mesmo grandes), montando assim um **_volume_** no *Deployment* declarando o local do container que aquele arquivo ir√° aparecer.

Vamos criar o arquivo [configmap.yaml](configmap.yaml) e declarar os comandos de configura√ß√£o. Por favor, abra-o para visualizar maiores detalhes e explica√ß√µes.

Ap√≥s finalizar o arquivo de ConfigMap acima, vamos utilizar este dentro do *Deployment* declarando-o atrav√©s do arquivo [deployment.yaml](deployment.yaml), adicionando o comando `spec.template.spec.volumes` para declarar os volumes, e logo ap√≥s vamos indicar que o container NGINX vai utilizar este volume atrav√©s do `spec.template.spec.containers.volumeMounts`. Abra este arquivo para visualizar mais detalhes.

Agora vamos aplicar a nossa ConfigMap: `kubectl apply -f configmap.yaml`. Para saber se funcionou vamos listar atrav√©s do `kubectl get configmaps`, retornando o seguinte:

```
NAME         DATA   AGE
nginx-conf   1      67s
```

Agora vamos fazer o *Deployment* com as novas configura√ß√µes de volumes via `kubectl apply -f deployment.yaml`. Lembrando que √© necess√°rio ver se os PODs de fato est√£o no ar via `kubctl get pods`.

Estando com o *service* no ar, vamos executar o comando `minikube service nginx-service` e ser√° aberto o navegador com a p√°gina inicial do NGINX. Podemos agora testar alterando o endere√ßo para `http://<ip-fornecido-pelo-minikube>:30586/google` e o redirecionando para o site da Google deveria funcionar.

## Configurando o MySQL do zero

Vamos criar os nossos arquivos de Kubernetes dentro [desta pasta](./mysql).

Primeiro vamos preparar o nosso arquivo de [deployment](./mysql/deployment.yaml) e fazer o teste subindo o mesmo. N√£o se esque√ßa que para verificar se o servi√ßo de MySQL subiu certinho temos que dar o comando `kubectl get pods`.